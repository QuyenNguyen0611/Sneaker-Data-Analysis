# -*- coding: utf-8 -*-
"""sneaker_sales_seasonality_and_forecast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RxoQYgR0ltBEN8ayvQ8zb-FlO4ZcNI7X
"""

# Load data for drive
from google.colab import drive
drive.mount('/content/drive')

!pip install numpy==1.24.4
!pip install pmdarima==2.0.4

import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objs as go
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.statespace.sarimax import SARIMAX
from pmdarima import auto_arima
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.stats.diagnostic import acorr_ljungbox
from scipy.fft import fft
from plotly.subplots import make_subplots

# Load the file
file_path = '/content/drive/MyDrive/Data Analysis Projects/sneaker_dataset.csv'
data = pd.read_csv(file_path)
data.head()

data.info()

"""The dataset contains 500 rows and 20 columns. Upon review, several columns appear redundant and can be removed to streamline the analysis.Notably, the current damaged and unsold rate values are in percentage format (e.g., 40, 50), so I plan to compute the damaged rate, sold rate, and unsold rate decimal format (e.g., 0.4, 0.5) for consistency and easier comparison.

# Data Cleaning
"""

# Remove redundancy columns month, year, quarter, date
data.drop(['month', 'year', 'quarter', 'date','sell_through_rate', 'damage_rate'], axis=1, inplace=True)

# Convert manfacturing_date and selling_date into datatime type
data['manufacturing_date'] = pd.to_datetime(data['manufacturing_date'])
data['selling_date'] = pd.to_datetime(data['selling_date'])

# Calculate damaged_rate, sold_rate, unsold_rate
data['damaged_rate'] = (data['damaged'] / data['total_produced'])
data['sold_rate'] = (data['total_sold'] / data['total_produced'])
data['unsold_rate'] = (data['unsold_inventory'] / data['total_produced'])

# Days between 'manufaturing_date' and 'selling_date' based on 'name' of sneaker
data['days'] = (data['selling_date'] - data['manufacturing_date']).dt.days

# Drop data if year = 2025 and 2015
data = data[data['selling_date'].dt.year != 2025]
data = data[data['selling_date'].dt.year != 2015]
data.info()

data.head()

#Save data to csv file and download
#data.to_csv('sneaker_dataset_cleaned.csv', index=False)
#from google.colab import files
#files.download('sneaker_dataset_cleaned.csv')

"""# Data Analysis
1. Trend of estimated revenue over time
2. The dataset have seasonality or not? Find average seasonal impact by month
3. Sneaker sales forecast for the next 12 months and peak season marks

### Estimated Revenue over time
"""

# Calculate total estimated revenue each year
total_estimated_revenue = data.groupby(data['selling_date'].dt.year)['estimated_revenue'].sum()
total_estimated_revenue

# Plot line chart for total_estimated_revenue
fig = go.Figure()
fig.add_trace(go.Scatter(x=total_estimated_revenue.index, y=total_estimated_revenue.values, mode='lines+markers', name='Total Estimated Revenue Over Time'))

"""The total estimated revenue has shown significant annual fluctuations between 2016 and 2024, peaking notably in 2022. However, following this peak, the chart indicates a consistent decline in estimated revenue from 2022 through 2024, reaching the lowest point in the displayed period.

## Seasonal impact by month
"""

monthly_sales = (
    data.groupby(data['selling_date'].dt.to_period('M'))['estimated_revenue']
    .sum()
    .to_timestamp()
)
monthly_sales

# Reset index to turn datetime index into a regular column
monthly_sales_df = monthly_sales.reset_index()
monthly_sales_df.rename(columns={'selling_date': 'date', 'estimated_revenue': 'sales'}, inplace=True)

# Extract month from date for color mapping
monthly_sales_df['month'] = monthly_sales_df['date'].dt.month
colors = {
    1: '#AEC6CF',
    2: '#FFB347',
    3: '#77DD77',
    4: '#FFD1DC',
    5: '#FDFD96',
    6: '#CBAACB',
    7: '#B39EB5',
    8: '#FFDAC1',
    9: '#E0BBE4',
    10: '#D5AAFF',
    11: '#B5EAD7',
    12: '#FF9AA2'
}

# Map color for each bar based on month
monthly_sales_df['color'] = monthly_sales_df['month'].map(colors)

# Create Plotly bar chart
fig = go.Figure()

fig.add_trace(go.Bar(
    x=monthly_sales_df['date'],
    y=monthly_sales_df['sales'],
    marker_color=monthly_sales_df['color'],  # Color bars by month
    name='Monthly Sales'
))

# Update chart layout
fig.update_layout(title='Monthly Sales',
                  yaxis_title='Estimated Revenue')

# Show interactive chart
fig.show()

"""An analysis of the sneaker revenue chart from 2016 to 2024 reveals a highly volatile sales pattern without a clear long-term upward or downward trend. The significant monthly fluctuations suggest that revenue is heavily influenced by short-term factors like promotional campaigns, new product launches, and external market events. While the overall historical data appears erratic, with major spikes in Feb-2018 and Mar-Apr 2020, a new seasonal trend seems to be forming. Notably, for the last three years, from 2022 to 2024, September has consistently marked the annual revenue peak, indicating an emerging and predictable high-sales period.

The preceding observations are based on visual analysis. To obtain an objective and quantitative assessment, the next step is to apply Time Series Decomposition. This method will clearly separate the Trend, Seasonality, and Residual components of the data.
"""

# Perform seasonal decomposition
decomposition = seasonal_decompose(monthly_sales, model='additive', period=12)

# Create subplots with 4 rows to display each component separately
fig = make_subplots(rows=4, cols=1, shared_xaxes=True,
                    vertical_spacing=0.05,
                    subplot_titles=('Observed', 'Trend', 'Seasonal', 'Residual'))

# Plot Observed component
fig.add_trace(go.Scatter(x=monthly_sales.index, y=decomposition.observed,
                         mode='lines', name='Observed', line=dict(color='blue')),
              row=1, col=1)

# Plot Trend component
fig.add_trace(go.Scatter(x=monthly_sales.index, y=decomposition.trend,
                         mode='lines', name='Trend', line=dict(color='orange')),
              row=2, col=1)

# Plot Seasonal component
fig.add_trace(go.Scatter(x=monthly_sales.index, y=decomposition.seasonal,
                         mode='lines', name='Seasonal', line=dict(color='green')),
              row=3, col=1)

# Plot Residual component as scatter points
fig.add_trace(go.Scatter(x=monthly_sales.index, y=decomposition.resid,
                         mode='markers', name='Residual', marker=dict(color='red')),
              row=4, col=1)

# Update overall layout
fig.update_layout(height=1000, width=1000,
                  title_text="Seasonal Decomposition of Monthly Sales (Plotly)",
                  showlegend=False)

# Show interactive chart
fig.show()

"""The Trend component shows noticeable fluctuations in the overall sales level over time. Peaks and troughs are clearly visible, indicating that, beyond short-term seasonal effects, the long-term sales trajectory experiences significant ups and downs. These fluctuations may be associated with external factors such as product launches, promotions, or market changes. Despite some recovery phases, there is no clear, consistent long-term upward or downward trend, suggesting that sales dynamics are highly event-driven rather than following a stable growth pattern.

The Seasonal component chart clearly shows a seasonal trend that repeats itself regularly over a 12-month cycle. The peaks and troughs repeat relatively consistently over the years, confirming that sneaker sales data has a clear and consistent seasonal element over the years.

The residual component appears randomly scattered around zero, with no obvious pattern or structure over time. This indicates that the decomposition model has successfully extracted the main trend and seasonal effects, leaving behind random fluctuations that likely represent irregular events, outliers, or noise in the data. Some large positive and negative spikes are visible, suggesting occasional extreme deviations, which could be due to unexpected events such as promotions, market disruptions, or external shocks. Overall, the residual pattern suggests that the model adequately captures the systematic structure in the data.
"""

# Create 'month' from seasonal component
seasonal_component = decomposition.seasonal
seasonal_df = seasonal_component.reset_index()
seasonal_df['month'] = seasonal_df['selling_date'].dt.month

# Group by month and calculate average value
monthly_seasonality = seasonal_df.groupby('month')[seasonal_component.name].mean()

# Create Plotly chart
fig = go.Figure()

fig.add_trace(go.Bar(
    x=monthly_seasonality.index,
    y=monthly_seasonality.values,
    marker_color='lightblue',
    name='Seasonal Impact'
))

# Customize layout
fig.update_layout(
    title='Average Seasonal Impact by Month',
    xaxis_title='Month',
    yaxis_title='Seasonal Impact',
    xaxis=dict(tickmode='linear'),
    yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black')
)

fig.show()

"""The bar chart illustrates the average seasonal effect on revenue for each month. Positive values indicate months where seasonal factors contribute to higher-than-average sales, while negative values indicate months with a downward seasonal influence.

* Months 2, 3, 4, 8, 9 and 12 exhibit a positive seasonal impact, suggesting these are typically strong sales months due to recurring seasonal patterns.

* Months 1, 5, 6, 7, 10, and 11 show a negative seasonal effect, indicating these periods are naturally weaker for sales.

* The most significant positive seasonal impact occurs in December, likely due to end-of-year shopping behavior.

* The most pronounced negative seasonal impact appears in January and June, potentially reflecting post-holiday slowdowns or off-peak buying periods.

## Predict revenue next year
"""

# Use auto_arima to choose best model
stepwise_model = auto_arima(monthly_sales,
                            start_p=0, start_q=0,
                            max_p=3, max_q=3,
                            seasonal=True, m=12,  # m=12 means 12 months
                            start_P=0, start_Q=0,
                            max_P=2, max_Q=2,
                            d=1, D=1,
                            trace=True,
                            error_action='ignore',
                            suppress_warnings=True,
                            stepwise=True)

# Summary the best model
print(stepwise_model.summary())

# Fit SARIMAX model with the best parameters
model = SARIMAX(monthly_sales,
                order=(0,1,3),
                seasonal_order=(0,1,1,12),
                enforce_stationarity=False,
                enforce_invertibility=False)

results = model.fit()

# Print model summary
print(results.summary())

# Forecast the next 12 months
forecast = results.get_forecast(steps=12)
forecast_mean = forecast.predicted_mean
forecast_ci = forecast.conf_int()

# Create Plotly figure
fig = go.Figure()

# Plot actual sales
fig.add_trace(go.Scatter(
    x=monthly_sales.index,
    y=monthly_sales.values,
    mode='lines',
    name='Actual Sales',
    line=dict(color='blue')
))

# Plot forecasted sales
fig.add_trace(go.Scatter(
    x=forecast_mean.index,
    y=forecast_mean.values,
    mode='lines+markers',
    name='Forecast',
    line=dict(color='red')
))

# Plot confidence interval as shaded area
fig.add_trace(go.Scatter(
    x=pd.concat([forecast_ci.index.to_series(), forecast_ci.index.to_series()[::-1]]),
    y=pd.concat([forecast_ci.iloc[:, 1], forecast_ci.iloc[:, 0][::-1]]),
    fill='toself',
    fillcolor='rgba(255, 0, 0, 0.2)',
    line=dict(color='rgba(255,255,255,0)'),
    showlegend=True,
    name='95% Confidence Interval'
))

# Update layout
fig.update_layout(
    title='Sneaker Sales Forecast with SARIMA (Plotly)',
    xaxis_title='Time',
    yaxis_title='Estimated Revenue',
    hovermode='x unified'
)

fig.show()

"""Based on the SARIMA forecast results:

* Sneaker sales are expected to fluctuate around the historical average over the next 12 months.
* Significant uncertainty remains, reflecting potential market volatility.

**Recommended actions:**

* Closely monitor actual monthly sales and adjust procurement plans accordingly.
* Focus promotional and marketing activities on the months identified as high season from previous analysis.
* Do not rely solely on statistical models; integrate market insights and upcoming sales campaigns to refine forecasts.


"""